{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hqU2Zyc_0Bl",
        "outputId": "02629ece-b3e6-4bcf-fb60-99e0d5456f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Sampling               Model        R2\n",
            "0   Sampling1        RandomForest  0.989100\n",
            "1   Sampling1                 SVM -0.329789\n",
            "2   Sampling1  LogisticRegression  0.651203\n",
            "3   Sampling2        RandomForest  0.985385\n",
            "4   Sampling2                 SVM -0.432292\n",
            "5   Sampling2  LogisticRegression  0.590774\n",
            "6   Sampling3        RandomForest  0.956251\n",
            "7   Sampling3                 SVM -0.531198\n",
            "8   Sampling3  LogisticRegression  0.453144\n",
            "9   Sampling4        RandomForest  0.883838\n",
            "10  Sampling4                 SVM -0.277778\n",
            "11  Sampling4  LogisticRegression  0.535354\n",
            "12  Sampling5        RandomForest  0.869318\n",
            "13  Sampling5                 SVM -0.263258\n",
            "14  Sampling5  LogisticRegression  0.564394\n",
            "\n",
            "Best results for each model:\n",
            "     Sampling               Model        R2\n",
            "2   Sampling1  LogisticRegression  0.651203\n",
            "0   Sampling1        RandomForest  0.989100\n",
            "13  Sampling5                 SVM -0.263258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/Creditcard_data.csv')\n",
        "\n",
        "# Check for class imbalance\n",
        "print(data['Class'].value_counts())\n",
        "\n",
        "# Balance the dataset using SMOTE\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "# Create a balanced dataset DataFrame\n",
        "balanced_data = pd.DataFrame(X_balanced, columns=X.columns)\n",
        "balanced_data['Class'] = y_balanced\n",
        "\n",
        "# Define sampling fractions\n",
        "sampling_fractions = [0.8, 0.6, 0.4, 0.3, 0.2]\n",
        "\n",
        "# Generate samples\n",
        "samples = [balanced_data.sample(frac=fraction, random_state=42) for fraction in sampling_fractions]\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(kernel='rbf', random_state=42),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "# Evaluate R^2 scores for each sampling technique and model\n",
        "results = []\n",
        "\n",
        "for i, sample in enumerate(samples, start=1):\n",
        "    X_sample = sample.drop('Class', axis=1)\n",
        "    y_sample = sample['Class']\n",
        "\n",
        "    # Split the sample into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, random_state=42)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate R^2 score\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        results.append({\n",
        "            'Sampling': f'Sampling{i}',\n",
        "            'Model': model_name,\n",
        "            'R2': r2\n",
        "        })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Print results\n",
        "print(results_df)\n",
        "\n",
        "# Determine the best sampling technique for each model\n",
        "best_results = results_df.loc[results_df.groupby('Model')['R2'].idxmax()]\n",
        "print(\"\\nBest results for each model:\")\n",
        "print(best_results)\n"
      ]
    }
  ]
}